---
excerpt: A comparative analysis of stylistic features used to identify authorship among four essayists using part-of-speech tagging, lexical diversity, and token metrics.
layout: single
author_profile: false
---

<section>
  <h2>Summary</h2>
  <div class="card">
    <p>
      For this project, I explored authorship identification using essays by four stylistically similar writers: David
Foster Wallace, Joan Didion, Zadie Smith, and John Jeremiah Sullivan. While these authors have some
similarities in their writing, my goal was to determine whether measures such as unique word count,
part-of-speech (POS) distribution, word length, lexical diversity, sentence length and Hapax Legomana can be used to identify an author.
    </p>
  </div>
</section>

<section>
  <h2>Methodology</h2>
  <div class="card">
    <h3>Data Collection and Preparation</h3>
    <p>
I selected a set of essays for each author based on availability, scraping text using a simple custom script.
Some sources did not permit scraping, resulting in fewer essays for certain authors. To expand the dataset,
I split each essay into chunks of three paragraphs. Chunks with word counts between 100 and 200 words
were kept.
To ensure balanced comparison, I randomly selected six chunks per author, based on the author with the
fewest qualifying chunks (meaning that it matched my requirement of 100-200 words).    </p>
<h3>Measures Used</h3>    
<p>
To investigate stylistic variation across authors, I calculated several measures for each chunk:
<ul><li>Part-of-speech (POS) tag counts using NLTK's pos_tag and the universal tagset.</li>
<li>Average unique word count per chunk.</li>
<li>Lexical diversity, calculated as:
<ul>
  <li>Lexical Diversity = (Number of unique tokens / Total tokens) * 100</li></ul>
<li>POS-specific trends, identifying outliers and stylistic patterns.</li>
    </ul>
  </div>
</section>

<section>
  <h2>Results</h2>

  <details class="card collapsible-section">
    <summary><strong>POS Tag Trends</strong></summary>
    <div class="card-content">
      <p><strong>Notable patterns:</strong></p>
      <ul>
        <li>David Foster Wallace had a significantly higher average count of nouns per essay, at 105.</li>
        <li>Joan Didion, John Jeremiah Sullivan, and Zadie Smith had lower noun counts and were all within 10 of one another:
        <ul>
          <li>Joan Didion: 35.7</li>
          <li>Zadie Smith: 35.3</li>
          <li>John Jeremiah Sullivan: 42.5</li>
        </ul>
        <li>Joan Didion had the lowest adverb use (8.8).</li>
        <li>Sullivan and Smith used more pronounsâ€”potentially indicating a more personal narrative style.</li>
        <li>Didion and Wallace had higher noun counts per chunk.</li>
      </ul>
    </div>
  </details>

  <details class="card collapsible-section">
    <summary><strong>Lexical Measures</strong></summary>
    <div class="card-content">
      <h4>Average Unique Word Count per Chunk</h4>
      <ul>
        <li>David Foster Wallace: 132</li>
        <li>John Jeremiah Sullivan: 110.8</li>
        <li>Zadie Smith: 102.8</li>
        <li>Joan Didion: 100.3</li>
      </ul>

      <h4>Average Lexical Diversity</h4>
      <ul>
        <li>David Foster Wallace: 61.3%</li>
        <li>John Jeremiah Sullivan: 63.1%</li>
        <li>Zadie Smith: 60%</li>
        <li>Joan Didion: 60.5%</li>
      </ul>
      <p>
        Wallace and Sullivan exhibited slightly higher lexical diversity, with Didion and Smith clustering slightly lower. These subtle distinctions suggest that lexical features may offer some predictive power, though the dataset is small.
      </p>
    </div>
  </details>
</section>

<section>
  <h2>Process</h2>

  <details class="card collapsible-section">
    <summary><strong>Data Collection & Sampling</strong></summary>
    <div class="card-content">
      <ul>
        <li>Custom Python scripts were used to extract and clean text.</li>
        <li>Each text was tokenized, POS-tagged, and filtered based on word count.</li>
        <li>Random chunk sampling ensured balanced representation per author.</li>
      </ul>
    </div>
  </details>

  <details class="card collapsible-section">
    <summary><strong>Analysis Pipeline</strong></summary>
    <div class="card-content">
      <ul>
        <li><code>nltk</code> for tokenization, POS tagging, and stopword filtering</li>
        <li><code>pandas</code> and <code>matplotlib</code> for data aggregation and visualization</li>
        <li>Calculated and visualized metrics: POS frequencies, unique word counts, lexical diversity</li>
      </ul>
    </div>
  </details>
</section>

<section>
  <h2>Tools & Technologies</h2>
  <div class="card">
    <ul>
      <li><strong>Languages:</strong> Python</li>
      <li><strong>Libraries:</strong> NLTK, pandas, matplotlib, scikit-learn</li>
      <li><strong>Data Format:</strong> Plain text, organized by author</li>
    </ul>
  </div>
</section>

<section>
  <div class="card code-link">
    <p><strong>Code:</strong> <a href="https://github.com/yourusername/your-repo-name" target="_blank">View on GitHub</a></p>
  </div>
</section>
